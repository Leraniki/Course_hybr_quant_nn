{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1feEBlSMnMi5SKmSnigntU6tysoE0JBoY",
      "authorship_tag": "ABX9TyM3G+FbuVtz834JEoR6qckx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leraniki/Course_hybr_quant_nn/blob/main/course_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение модели"
      ],
      "metadata": {
        "id": "olf28JBi2cPJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M89QeDX4ySyZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wbTFf4_W1qFx",
        "outputId": "36aaa0e0-ab68-4841-abb4-e6a5bc110309"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка модели"
      ],
      "metadata": {
        "id": "5AiqN2e13CRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LNGkWm6_8Qxa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Настройки и Данные\n",
        "model_name = \"sberbank-ai/ruRoberta-large\"\n",
        "file_path = 'data.txt'\n",
        "\n",
        "with open (file_path, 'r', encoding = 'utf-8') as f:\n",
        "    texts = [line.strip() for line in f.readlines() if len(line.strip()) > 10]\n",
        "    print(f\"Загружено {len(texts)} предложений из файла {file_path}\")\n",
        "\n",
        "# 2. Токенизатор и Датасет\n",
        "print(\"Загружаем токенизатор...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "class SimpleTextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=64):\n",
        "        self.encodings = tokenizer(texts, return_tensors='pt', max_length=max_length, truncation=True,\n",
        "                                   padding='max_length')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "\n",
        "dataset = SimpleTextDataset(texts, tokenizer)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
        "\n",
        "# 3. Загрузка ПРЕДОБУЧЕННОЙ модели\n",
        "print(f\"Загружаем веса модели {model_name}...\")\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB7a7ce42-sh",
        "outputId": "133887d8-140b-430a-f918-5a408656e2ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружено 226 предложений из файла data.txt\n",
            "Загружаем токенизатор...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружаем веса модели sberbank-ai/ruRoberta-large...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Само обучение"
      ],
      "metadata": {
        "id": "SS1Rv3GG3HWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Цикл Обучения (Fine-tuning)\n",
        "batch_size = 4\n",
        "epochs = 5\n",
        "learning_rate = 2e-5\n",
        "\n",
        "print(f\"Начинаем дообучение на {device}...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            active_loss = labels.view(-1) != -100\n",
        "\n",
        "            flat_preds = predictions.view(-1)[active_loss].cpu().numpy()\n",
        "            flat_labels = labels.view(-1)[active_loss].cpu().numpy()\n",
        "\n",
        "            all_preds.extend(flat_preds)\n",
        "            all_labels.extend(flat_labels)\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    acc = accuracy_score(all_labels, all_preds) if all_labels else 0\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} | Loss: {avg_loss:.4f} | Accuracy: {acc:.4f}\")\n",
        "\n",
        "# 5. Демонстрация работы\n",
        "print(\"\\n--- Тест модели ---\")\n",
        "model.eval()\n",
        "\n",
        "test_sentence = \"Опекуны и [MASK] несовершеннолетних граждан обязаны проживать совместно со своими подопечными. \"\n",
        "\n",
        "inputs = tokenizer(test_sentence, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
        "predicted_word = tokenizer.decode(predicted_token_id)\n",
        "\n",
        "print(f\"Запрос: {test_sentence}\")\n",
        "print(f\"Реультат: {predicted_word}\")\n",
        "\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/Курсовая/model\"\n",
        "\n",
        "# 1. Сохраняем и веса, и токенизатор\n",
        "print(f\"Сохраняем модель в папку {output_dir}...\")\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(\"Готово! Модель сохранена.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC3eninLznU6",
        "outputId": "94e448ef-9a6b-4c3a-8cd6-57fe69f3494c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем дообучение на cuda...\n",
            "Epoch 1/5 | Loss: 1.1131 | Accuracy: 0.7710\n",
            "Epoch 2/5 | Loss: 1.1287 | Accuracy: 0.7639\n",
            "Epoch 3/5 | Loss: 0.9206 | Accuracy: 0.7997\n",
            "Epoch 4/5 | Loss: 0.6547 | Accuracy: 0.8382\n",
            "Epoch 5/5 | Loss: 0.5660 | Accuracy: 0.8568\n",
            "\n",
            "--- Тест модели ---\n",
            "Запрос: Опекуны и [MASK] несовершеннолетних граждан обязаны проживать совместно со своими подопечными. \n",
            "Реультат: \n",
            "Сохраняем модель в папку /content/drive/MyDrive/Курсовая/model...\n",
            "Готово! Модель сохранена.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестирование"
      ],
      "metadata": {
        "id": "bW1SDeET2hA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/Курсовая/model\"\n",
        "\n",
        "print(f\"Загружаю обученную модель из {model_path}...\")\n",
        "\n",
        "try:\n",
        "    # Загружаем не из интернета, а из твоей папки!\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
        "except OSError:\n",
        "    print(\"Ошибка! Не найдена папка с моделью. Укажи правильный путь.\")\n",
        "    exit()\n",
        "\n",
        "# Если есть видеокарта - используем, нет - и процессор справится быстро\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.eval() # Переключаем в режим \"экзамена\" (отключаем обучение)\n",
        "\n",
        "print(\"\\n=== МОДЕЛЬ ГОТОВА К РАБОТЕ ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQD3v8PL7emC",
        "outputId": "268844a5-291f-4e9a-cc8e-5309f16e7aac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружаю обученную модель из /content/drive/MyDrive/Курсовая/model...\n",
            "\n",
            "=== МОДЕЛЬ ГОТОВА К РАБОТЕ ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Используй токен {tokenizer.mask_token} чтобы скрыть слово.\")\n",
        "print(\"Пример: Договор вступает в [MASK] с момента подписания.\")\n",
        "print(\"Для выхода напиши: exit\")\n",
        "\n",
        "while True:\n",
        "    print(\"-\" * 30)\n",
        "    user_text = input(\"Введи предложение: \")\n",
        "\n",
        "    if user_text.lower() in ['exit', 'quit', 'выход']:\n",
        "        break\n",
        "\n",
        "    # Проверка, есть ли маска в тексте\n",
        "    if tokenizer.mask_token not in user_text:\n",
        "        # Если пользователь забыл маску, но использовал [MASK], заменим сами (для удобства)\n",
        "        if \"[MASK]\" in user_text and tokenizer.mask_token != \"[MASK]\":\n",
        "             user_text = user_text.replace(\"[MASK]\", tokenizer.mask_token)\n",
        "        elif \"<mask>\" in user_text: # Для RoBERTa\n",
        "             pass\n",
        "        else:\n",
        "            print(f\"⚠ Внимание: Ты не добавила маску! Используй {tokenizer.mask_token} или [MASK]\")\n",
        "            continue\n",
        "\n",
        "    # Подготовка данных\n",
        "    inputs = tokenizer(user_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Предсказание\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # Находим индекс маски в предложении\n",
        "    # (Если масок несколько, найдем первую)\n",
        "    mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "\n",
        "    if len(mask_token_index) == 0:\n",
        "        print(\"Что-то пошло не так, не могу найти маску.\")\n",
        "        continue\n",
        "\n",
        "    # Берем индекс первой маски\n",
        "    idx = mask_token_index[0]\n",
        "\n",
        "    # Находим топ-5 самых вероятных слов\n",
        "    top_k = 5\n",
        "    probs = torch.nn.functional.softmax(logits[0, idx], dim=-1)\n",
        "    top_k_weights, top_k_indices = torch.topk(probs, top_k, sorted=True)\n",
        "\n",
        "    print(f\"\\nМодель думает, что пропущено:\")\n",
        "    for i in range(top_k):\n",
        "        token_id = top_k_indices[i].item()\n",
        "        word = tokenizer.decode([token_id]).strip()\n",
        "        probability = top_k_weights[i].item() * 100\n",
        "        print(f\"{i+1}. {word} ({probability:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AMd8ENJ2gVp",
        "outputId": "285397ef-4d7d-4e88-b9a2-68c719f019b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Используй токен <mask> чтобы скрыть слово.\n",
            "Пример: Договор вступает в [MASK] с момента подписания.\n",
            "Для выхода напиши: exit\n",
            "------------------------------\n",
            "Введи предложение: Опекун не [MASK] без предварительного разрешения органа опеки и попечительства совершать, а попечитель - давать согласие на совершение сделок по отчуждению\n",
            "\n",
            "Модель думает, что пропущено:\n",
            "1. вправе (97.7%)\n",
            "2. может (1.7%)\n",
            "3. должен (0.4%)\n",
            "4. обязан (0.1%)\n",
            "5. права (0.0%)\n",
            "------------------------------\n",
            "Введи предложение: Гражданин может быть объявлен судом , если в месте его жительства нет сведений о месте его пребывания в течение пяти лет\n",
            "⚠ Внимание: Ты не добавила маску! Используй <mask> или [MASK]\n",
            "------------------------------\n",
            "Введи предложение: Гражданин может быть объявлен судом <mask>, если в месте его жительства нет сведений о месте его пребывания в течение пяти лет\n",
            "\n",
            "Модель думает, что пропущено:\n",
            "1. мертвым (52.5%)\n",
            "2. больным (16.8%)\n",
            "3. таковым (15.0%)\n",
            "4. розыск (4.5%)\n",
            "5. виновным (1.5%)\n",
            "------------------------------\n",
            "Введи предложение: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWSSliep8fmp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}